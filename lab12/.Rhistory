barplot(unname(prop.table(table(dat$sentiment))), horiz = TRUE)
# Graph the relative frequencies (i.e. proportions) with a horizontal barplot (bars horizontally oriented) in decreasing order, including names of sentiment types.
barplot(unname(prop.table(table(dat$sentiment))), names.arg = levels(dat$sentiment), horiz = TRUE)
# What are the different types of sentiments?
levels(dat$sentiment)
# Graph the relative frequencies (i.e. proportions) with a horizontal barplot (bars horizontally oriented) in decreasing order, including names of sentiment types.
barplot(unname(prop.table(table(dat$sentiment))), names.arg = levels(dat$sentiment), horiz = TRUE)
# Graph the relative frequencies (i.e. proportions) with a horizontal barplot (bars horizontally oriented) in decreasing order, including names of sentiment types.
barplot(unname(prop.table(table(dat$sentiment))), names.arg = levels(dat$sentiment), horiz = TRUE, xlab = "Sentiments")
# Graph the relative frequencies (i.e. proportions) with a horizontal barplot (bars horizontally oriented) in decreasing order, including names of sentiment types.
barplot(unname(prop.table(table(dat$sentiment))), names.arg = levels(dat$sentiment), horiz = TRUE, xlab = "Frequency", ylab = "Sentiments")
data.frame(prop.table(table(dat$sentiment))
freq <- data.frame(prop.table(table(dat$sentiment))
freq <- data.frame(prop.table(table(dat$sentiment)))
View(freq)
ggplot(freq, aes(x = reorder(Var1, Freq), y = Freq)) +  geom_bar(stat = "identity") + coord_flip() + xlab("Team") + ylab("Salary") + ggtitle("Relative Frequencies of Sentiments")
# Graph the relative frequencies (i.e. proportions) with a horizontal barplot (bars horizontally oriented) in decreasing order, including names of sentiment types.
freq <- data.frame(prop.table(table(dat$sentiment)))
ggplot(freq, aes(x = reorder(Var1, Freq), y = Freq)) +  geom_bar(stat = "identity") + coord_flip() + xlab("Sentiments") + ylab("Frequencies") + ggtitle("Relative Frequencies of Sentiments")
?table
table(row.names = levels(dat$sentiment))
for (i in levels(dat$sentiment)) {
sent_tbl[j] = mean(nchar(dat$content[sentiment = i]))
}
j <- toString(i)
sent_tbl <- table(row.names = levels(dat$sentiment))
for (i in levels(dat$sentiment)) {
j <- toString(i)
sent_tbl[j] = mean(nchar(dat$content[sentiment = i]))
}
sent_tbl[j] = mean(nchar(toString(dat$content[sentiment = i]))
}
for (i in levels(dat$sentiment)) {
sent_tbl[j] = mean(nchar(toString(dat$content[sentiment = i])))
sent_tbl <- table(row.names = levels(dat$sentiment))
for (i in levels(dat$sentiment)) {
sent_tbl[j] = mean(nchar(toString(dat$content[sentiment = i])))
}
sent_tbl
)
for (i in levels(dat$sentiment)) {
sent_tbl[j] = mean(nchar(toString(dat$content[sentiment = i])))
}
sent_tbl[i] = mean(nchar(toString(dat$content[sentiment = i])))
sent_tbl <- table(row.names = levels(dat$sentiment))
for (i in levels(dat$sentiment)) {
sent_tbl[i] = mean(nchar(toString(dat$content[sentiment = i])))
}
levels(dat$sentiment)
levels(dat$sentiment)[1]
typeof(levels(dat$sentiment)[1])
for (i in levels(dat$sentiment)) {
sent_tbl[i] = mean(nchar(toString(dat$content[sentiment = i])))
}
library(dplyr)
dat <- read.csv("text_emotion.csv")
# Count the number of characters in the tweet contents
char_count <- rep(0, 40000)
for (i in 1:40000) {
char_count[i] = nchar(toString(dat$content[i]))
}
summary(char_count)
hist(char_count, breaks = seq(0, 180, by = 5), main = "Histogram of Character Count", xlab = "Character Count")
# Are there any tweets with 0 characters?
any(char_count == 0)
# Are there any tweets with 1 character?
any(char_count == 1)
# How many?
length(char_count[char_count == 1])
# What is their content?
dat$content[char_count == 1]
# What is their location (i.e. index or position)?
which(char_count %in% 1)
# What is the tweet with the most characters?
dat$tweet_id[max(char_count)]
# the number of characters
max(char_count)
# display its content
dat$content[max(char_count)]
# what is its location (i.e. index or position)?
which(char_count %in% max(char_count))
library(ggplot2)
# What are the different types of sentiments?
levels(dat$sentiment)
# Compute the frequencies (i.e. counts) of each sentiment (and display these frequencies).
table(dat$sentiment)
# Graph the relative frequencies (i.e. proportions) with a horizontal barplot (bars horizontally oriented) in decreasing order, including names of sentiment types.
freq <- data.frame(prop.table(table(dat$sentiment)))
ggplot(freq, aes(x = reorder(Var1, Freq), y = Freq)) +  geom_bar(stat = "identity") + coord_flip() + xlab("Sentiments") + ylab("Frequencies") + ggtitle("Relative Frequencies of Sentiments")
# Sentiment and length of tweets: compute a table with the average length of characters per sentiment (i.e. average number of characters for neutral tweets, for happy tweets, etc.). Display this table.
sent_tbl <- table(row.names = levels(dat$sentiment))
for (i in levels(dat$sentiment)) {
sent_tbl[i] = mean(nchar(toString(dat$content[sentiment = i])))
}
sent_tbl[i] = mean(nchar(toString(dat$content[sentiment == i])))
for (i in levels(dat$sentiment)) {
sent_tbl[i] = mean(nchar(toString(dat$content[sentiment == i])))
}
sent_tbl[i] = mean(nchar(toString(dat$content[dat$sentiment == i])))
sent_tbl <- table(row.names = levels(dat$sentiment))
for (i in levels(dat$sentiment)) {
sent_tbl[i] = mean(nchar(toString(dat$content[dat$sentiment == i])))
}
nchar(toString(dat$content[dat$sentiment == i]))
toString(dat$content[dat$sentiment == i])
dat$content[dat$sentiment == i]))
sent_tbl[i] = nchar(toString(dat$content[dat$sentiment == i])) / length(dat[dat.sentiment == i])
sent_tbl <- table(row.names = levels(dat$sentiment))
for (i in levels(dat$sentiment)) {
sent_tbl[i] = nchar(toString(dat$content[dat$sentiment == i])) / length(dat[dat.sentiment == i])
}
for (i in levels(dat$sentiment)) {
sent_tbl[i] = nchar(toString(dat$content[dat$sentiment == i])) / length(dat[dat$sentiment == i])
}
length(dat[dat$sentiment == i])
length(dat[dat$sentiment = i])
length(dat[dat$sentiment == i])
length(dat[dat$sentiment == i])
dat[dat$sentiment == i]
dat[dat$sentiment == "anger"]
dat[dat$sentiment == "worry"]
sent_tbl[i] = nchar(toString(dat$content[dat$sentiment == i])) / length(dat$content[dat$sentiment == i])
sent_tbl <- table(row.names = levels(dat$sentiment))
for (i in levels(dat$sentiment)) {
sent_tbl[i] = nchar(toString(dat$content[dat$sentiment == i])) / length(dat$content[dat$sentiment == i])
}
sent_tbl
# No longer than 15 characters (if you find usernames longer than 15 characters, display them)
dat$author[nchar(dat$author) > 15]
# No longer than 15 characters (if you find usernames longer than 15 characters, display them)
dat$author[nchar(toString(dat$author)) > 15]
nchar(toString(dat$author))
typeof(dat$tweet_id)
typeof(dat$sentiment)
dat$author = toString(dat$author)
typeof(dat$author)
dat$sentiment = toString(dat$sentiment)
dat$content = toString(dat$content)
dat <- read.csv("text_emotion.csv")
dat$author = toString(dat$author)
dat$content = toString(dat$content)
dat$sentiment = toString(dat$sentiment)
# Count the number of characters in the tweet contents
char_count <- rep(0, 40000)
for (i in 1:40000) {
char_count[i] = nchar(dat$content[i])
}
# Count the number of characters in the tweet contents
char_count <- nchar(dat$content[i])
# Count the number of characters in the tweet contents
char_count <- rep(0, 40000)
for (i in 1:40000) {
char_count[i] = nchar(dat$content[i])
}
nchar(dat$content[1])
View(dat)
dat <- read.csv("text_emotion.csv")
dat <- read.csv("text_emotion.csv")
# Count the number of characters in the tweet contents
char_count <- rep(0, 40000)
knitr::opts_chunk$set(echo = TRUE)
library(dplyr)
dat <- read.csv("text_emotion.csv")
# Count the number of characters in the tweet contents
char_count <- rep(0, 40000)
for (i in 1:40000) {
char_count[i] = nchar(toString(dat$content[i]))
}
summary(char_count)
hist(char_count, breaks = seq(0, 180, by = 5), main = "Histogram of Character Count", xlab = "Character Count")
# Are there any tweets with 0 characters?
any(char_count == 0)
# Are there any tweets with 1 character?
any(char_count == 1)
# How many?
length(char_count[char_count == 1])
# What is their content?
dat$content[char_count == 1]
# What is their location (i.e. index or position)?
which(char_count %in% 1)
# What is the tweet with the most characters?
dat$tweet_id[max(char_count)]
# the number of characters
max(char_count)
# display its content
dat$content[max(char_count)]
# what is its location (i.e. index or position)?
which(char_count %in% max(char_count))
library(ggplot2)
# What are the different types of sentiments?
levels(dat$sentiment)
# Compute the frequencies (i.e. counts) of each sentiment (and display these frequencies).
table(dat$sentiment)
# Graph the relative frequencies (i.e. proportions) with a horizontal barplot (bars horizontally oriented) in decreasing order, including names of sentiment types.
freq <- data.frame(prop.table(table(dat$sentiment)))
ggplot(freq, aes(x = reorder(Var1, Freq), y = Freq)) +  geom_bar(stat = "identity") + coord_flip() + xlab("Sentiments") + ylab("Frequencies") + ggtitle("Relative Frequencies of Sentiments")
# Sentiment and length of tweets: compute a table with the average length of characters per sentiment (i.e. average number of characters for neutral tweets, for happy tweets, etc.). Display this table.
sent_tbl <- table(row.names = levels(dat$sentiment))
for (i in levels(dat$sentiment)) {
sent_tbl[i] = nchar(toString(dat$content[dat$sentiment == i])) / length(dat$content[dat$sentiment == i])
}
sent_tbl
author_count <- rep(0, 40000)
for (i in 1:40000) {
author_count[i] = nchar(toString(dat$author[i]))
}
# No longer than 15 characters (if you find usernames longer than 15 characters, display them)
dat$author[author_count > 15]
# Contain alphanumeric characters and underscores (if you find usernames containing other symbols, display them)
dat$author[which(dat$author %in% c(LETTER, "_")]
# No longer than 15 characters (if you find usernames longer than 15 characters, display them)
dat$author[author_count > 15]
# No longer than 15 characters (if you find usernames longer than 15 characters, display them)
any(author_count > 15)
# Contain alphanumeric characters and underscores (if you find usernames containing other symbols, display them)
any(dat$author %in% c(LETTER, "_"))
# Contain alphanumeric characters and underscores (if you find usernames containing other symbols, display them)
any(dat$author %in% c(LETTERS, "_"))
View(dat)
# What is the number of characters of the shortest usernames? And what are the names of these authors? (write commands to answer these questions)
min(author_count)
dat$author[min(author_count)]
dat$author[which(dat$author %in% min(author_count))]
dat$author[author_Count == min(author_count)]
dat$author[author_count == min(author_count)]
# display its content
dat$content[char_count == max(char_count)]
?grepl
# Contain alphanumeric characters and underscores (if you find usernames containing other symbols, display them)
grepl("[A-Za-z]", dat$author)
# Contain alphanumeric characters and underscores (if you find usernames containing other symbols, display them)
grepl("[^A-Za-z]", dat$author)
# Contain alphanumeric characters and underscores (if you find usernames containing other symbols, display them)
grepl("^[A-Za-z0-9_]*$", dat$author)
?any_vars
?any
# Contain alphanumeric characters and underscores (if you find usernames containing other symbols, display them)
any(grepl("^[A-Za-z0-9_]*$", dat$author))
# Contain alphanumeric characters and underscores (if you find usernames containing other symbols, display them)
any(!grepl("^[A-Za-z0-9_]*$", dat$author))
which(any(grepl("^[A-Za-z0-9_]*$", dat$author)) %in% "FALSE")
which(any(grepl("^[A-Za-z0-9_]*$", dat$author)) %in% FALSE)
# Contain alphanumeric characters and underscores (if you find usernames containing other symbols, display them)
all(grepl("^[A-Za-z0-9_]*$", dat$author))
?all
dat$author[grepl("^[A-Za-z0-9_]*$", dat$author) == FALSE]
# How many tweets contain at least one caret symbol "ˆ" (write a command to answer this question).
length(dat[grepl("^[^]*$", dat$content) == TRUE])
/\^/
# How many tweets contain at least one caret symbol "ˆ" (write a command to answer this question).
length(dat[grepl("[/\^/]", dat$content) == TRUE])
# How many tweets contain at least one caret symbol "ˆ" (write a command to answer this question).
length(dat[grepl("^", dat$content) == TRUE])
# How many tweets contain at least one caret symbol "ˆ" (write a command to answer this question).
length(dat[grepl("\\^", dat$content) == TRUE])
which(any(grepl("^[A-Za-z0-9_]*$", dat$author)) %in% "FALSE")
grepl("\\^", dat$content)
any(grepl("\\^", dat$content))
length(dat)
# How many tweets contain at least one caret symbol "ˆ" (write a command to answer this question).
length(dat$content[grepl("\\^", dat$content) == TRUE])
# How many tweets contain at least one caret symbol "ˆ" (write a command to answer this question).
length(dat$content[grepl("^", dat$content) == TRUE])
# How many tweets contain at least one caret symbol "ˆ" (write a command to answer this question).
length(dat$content[grepl("\\^", dat$content) == TRUE])
# How many tweets contain three or more consecutive dollar symbols "$" (write a command to answer this question).
length(dat$content[grepl("\$$$*", dat$content) == TRUE])
# How many tweets contain three or more consecutive dollar symbols "$" (write a command to answer this question).
length(dat$content[grepl("$$$*", dat$content) == TRUE])
# How many tweets contain three or more consecutive dollar symbols "$" (write a command to answer this question).
length(dat$content[grepl("\\$$$*", dat$content) == TRUE])
# How many tweets do NOT contain the characters "a" or "A" (write a command to answer this question).
length(dat$content[grepl("^[Aa]", dat$content) == TRUE])
# How many tweets do NOT contain the characters "a" or "A" (write a command to answer this question).
length(dat$content[grepl("[^Aa]", dat$content) == TRUE])
# How many tweets do NOT contain the characters "a" or "A" (write a command to answer this question).
length(dat$content[grepl("^[Aa]", dat$content) == TRUE])
# How many tweets do NOT contain the characters "a" or "A" (write a command to answer this question).
length(dat$content[grepl("^[Aa]*", dat$content) == TRUE])
# How many tweets do NOT contain the characters "a" or "A" (write a command to answer this question).
length(dat$content[grepl("^[Aa]", dat$content) == TRUE])
# Display the first 10 elements of the tweets that do NOT contain the characters "a" or "A" (write a command to answer this question).
head(dat$content[grepl("^[Aa]", dat$content) == TRUE], 10)
# Display the first 10 elements of the tweets that do NOT contain the characters "a" or "A" (write a command to answer this question).
head(dat[grepl("^[Aa]", dat$content) == TRUE], 10)
# Display the first 10 elements of the tweets that do NOT contain the characters "a" or "A" (write a command to answer this question).
head(dat$content[grepl("^[Aa]", dat$content) == TRUE], 10)
dat[,1]
library(stringr)
# Number of exclamation symbols "!": compute a vector with the number of exclamation symbols in each tweet, and display its summary().
num_ex <- rep(0, 40000)
for (i in 1:40000) {
num_ex[i] = str_count(dat$content, "!")
}
# Number of exclamation symbols "!": compute a vector with the number of exclamation symbols in each tweet, and display its summary().
num_ex <- rep(0, 40000)
for (i in 1:40000) {
num_ex[i] = str_count(dat$content[i], "!")
}
# What’s the tweet (content) with the largest number of exclamation symbols !? Display its content. (write a command to answer this question)
dat$content[num_ex == max(num_ex)]
?grepl
# How many tweets contain the individual strings "omg" or "OMG" (write a command to answer this question).
length(dat$content[grepl("omg", dat$content, ignore.case = TRUE) == TRUE])
knitr::opts_chunk$set(echo = TRUE)
library(XML)
library(xml2)
install.packages("xml2")
library(xml2)
install.packages("xml2")
install.packages("xml2")
install.packages(xml2)
install.packages("xml2")
install.packages("xml2")
library(rvest)
library(magrittr)
install.packages("rvest")
install.packages("rvest")
knitr::opts_chunk$set(echo = TRUE)
library(xml2)
library(rvest)
library(XML)
library(xml2)
library(rvest)
library(magrittr)
# Assemble url (so it fits on screen)
basket_gsw <- "https://www.basketball-reference.com/teams/GSW/2017.html"
gsw_url <- basket_gsw
# download HTML file to your working directory
download.file(gsw_url, 'gsw-roster-2017.html')
# Assemble url (so it fits on screen)
gsw_url <- "https://www.basketball-reference.com/teams/GSW/2017.html"
# download HTML file to your working directory
download.file(gsw_url, 'gsw-roster-2017.html')
# Read GSW Roster html table
gsw_roster <- readHTMLTable('gsw-roster-2017.html')
bos_url <- "https://www.basketball-reference.com/teams/BOS/2017.html"
download.file(bos_url, 'bos-roster-2017.html')
bos_roster <- readHTMLTable('bos-roster-2017.html')
nba_html <- "https://www.basketball-reference.com/leagues/NBA_2017.html"
xml_doc <- read_html(nba_html)
xml_text <- xml_doc %>% html_text()
# content of h2 nodes
xml_doc %>%
html_nodes("h2") %>%
html_text()
View(xml_doc)
nba_html <- "https://www.basketball-reference.com/leagues/NBA_2017.html"
xml_doc <- read_html(nba_html)
xml_text <- xml_doc %>% html_text()
# content of h2 nodes
xml_doc %>%
html_nodes("h2") %>%
html_text()
# content of h1
xml_doc %>%
html_nodes("h1") %>%
html_text()
# content of strong
xml_doc %>%
html_nodes("strong") %>%
html_text()
# content of button
xml_doc %>%
html_nodes("button") %>%
html_text()
# node with an attribute
xml_doc %>%
html_nodes("p.listhead") %>%
html_text()
# p.listhead nodes
xml_doc %>%
html_nodes(xpath = '//p[@class="listhead"]') %>%
html_text()
# extracting second table
xml_table2 <- xml_doc %>%
html_nodes("table") %>%
extract(2)
# extracting first table
xml_table1 <- xml_doc %>%
html_nodes("table") %>%
extract(1)
class(xml_table1)
tbl1 <- html_table(xml_table1)
head(tbl1)
# extracting second table
xml_table2 <- xml_doc %>%
html_nodes("table") %>%
extract(2)
# extract names of teams
xml_tables %>%
html_nodes("a") %>%
html_text()
# extracting first table
xml_table1 <- xml_doc %>%
html_nodes("table") %>%
extract(1)
class(xml_table1)
tbl1 <- html_table(xml_table1)
head(tbl1)
# extracting second table
xml_table2 <- xml_doc %>%
html_nodes("table") %>%
extract(2)
# two html tables
xml_tables <- xml_doc %>%
html_nodes("table") %>%
extract(1:2)
# extract names of teams
xml_tables %>%
html_nodes("a") %>%
html_text()
# href attributes
xml_tables %>%
html_nodes("a") %>%
html_attr("href")
# Store the href attributes in a character vector hrefs.
herfs_vec <- xml_tables %>%
html_nodes("a") %>%
html_attr("href")
xml_tables %>%
html_nodes("a") %>%
html_text()
# href attributes
xml_tables %>%
html_nodes("a") %>%
html_attr("href")
# Use string manipulation functions to create a character vector teams that contains just the team abbreviations: e.g. "BOS", "CLE", "TOR", ...
team_abv <- substr(herfs_vec, 8, 11)
team_abv
# Use string manipulation functions to create a character vector teams that contains just the team abbreviations: e.g. "BOS", "CLE", "TOR", ...
team_abv <- substr(herfs_vec, 8, 10)
team_abv
# href attributes
xml_tables %>%
html_nodes("a") %>%
html_attr("href")
# extract names of teams
xml_tables %>%
html_nodes("a") %>%
html_text()
# extracting first table
xml_table1 <- xml_doc %>%
html_nodes("table") %>%
extract(1)
View(xml_table1)
View(xml_table2)
# Create a character vector files with elements: "BOS-roster-2017.csv", "CLE-roster-2017.csv", "TOR-roster-2017.csv", ...
csv_files <- paste0(team_abv, "-roster-2017.csv")
csv_files
# Use the object basket and the first element of hrefs (i.e. hrefs[1]) to assemble a team_url like the one used for gsw_url:
basket <- "https://www.basketball-reference.com"
hrefs[1]
# href attributes
xml_tables %>%
html_nodes("a") %>%
html_attr("href")
# Store the href attributes in a character vector hrefs.
herfs <- xml_tables %>%
html_nodes("a") %>%
html_attr("href")
team_url <- paste0(basket, herfs)
team_url
herfs[1]
read_html(team_url)
read_html(team_url)
read_html(team_url[1])
team_url <- paste0(basket[1], herfs)
# Read the html document of team_url.
read_html(team_url)
team_url <- paste0(basket, herfs[1])
# Read the html document of team_url.
read_html(team_url)
?html_table
# Use html_table() to extract the content of the html table as a data frame called roster.
roster <- html_table(read_html(team_url))
View(roster)
View(roster)
# Use html_table() to extract the content of the html table as a data frame called roster.
roster <- html_table(team_url)
# Use html_table() to extract the content of the html table as a data frame called roster.
roster <- html_table(read_html(team_url))
# Use html_table() to extract the content of the html table as a data frame called roster.
team_table1 <- read_html(team_url) %>%
html_nodes("table") %>%
extract(1)
roster <- html_table(read_html(team_url))
View(roster)
View(xml_table1)
View(roster)
roster[2]
setwd("~/Desktop/hw-stat133/lab12")
# Store the data frame in a csv file: "BOS-roster-2017.csv".
write.csv(roster, "BOS-roster-2017.csv")
herfs
roster <- html_table(read_html(team_url))
# Use html_table() to extract the content of the html table as a data frame called roster.
roster <- html_table(read_html(team_url))
for (i in team_abv) {
csv_files1 <- paste0(i, "-roster-2017.csv")
team_url1 <- paste0(basket, "/teams/", i, "/2017.html")
roster1 <- html_table(read_html(team_url1))
write.csv(roster1, i, "-roster-2017.csv")
}
# Create a for () loop to extract a handful of the roster tables as data frames.
# Store each table in its own csv file: e.g. "GSW-roster-2017.csv"
for (i in team_abv) {
csv_files1 <- paste0(i, "-roster-2017.csv")
team_url1 <- paste0(basket, "/teams/", i, "/2017.html")
roster1 <- html_table(read_html(team_url1))
write.csv(roster1, paste0(i, "-roster-2017.csv"))
}
